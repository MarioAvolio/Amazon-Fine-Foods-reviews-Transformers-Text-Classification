{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioAvolio/Amazon-Fine-Foods-reviews-Transformers-Text-Classification/blob/main/Amazon_Fine_Food_Review_Text_Classification_with_Standard_approaches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owaHBQRxPfPD"
      },
      "source": [
        "# Text Classification: a \"standard\" approach\n",
        "\n",
        "\n",
        "**Mario Avolio: 880995 - https://marioavolio.netlify.app/**\n",
        "\n",
        "Credits: \n",
        "- https://www.oreilly.com/library/view/practical-natural-language/9781492054047/\n",
        "\n",
        "Dataset:\n",
        "- https://snap.stanford.edu/data/web-FineFoods.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsRizD7zFJ3V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ6-kXG-0p7V",
        "outputId": "9fd791c2-5e85-4036-f451-8c29bcf7db8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfUllriJXH6V"
      },
      "source": [
        "# Constants and Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hhFPP6_GZvC"
      },
      "outputs": [],
      "source": [
        "PATH_PROJ = \"/content/drive/MyDrive/data-proj/\"\n",
        "# if not os.path.exists(PATH_PROJ):\n",
        "#   PATH_PROJ = \"/content/drive/MyDrive/shared/data-proj/\"\n",
        "\n",
        "PATH_DATASET = PATH_PROJ+\"preprocessed.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcr0tZ5tKrtb"
      },
      "source": [
        "\n",
        "# Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "IJar8wRnGxx5",
        "outputId": "f797ae66-ae7f-44d1-ff4b-4611eda539e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [text, score]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e33e0a8-10ce-4b90-b589-9e5333c9ad21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e33e0a8-10ce-4b90-b589-9e5333c9ad21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e33e0a8-10ce-4b90-b589-9e5333c9ad21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e33e0a8-10ce-4b90-b589-9e5333c9ad21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "df = pd.read_csv(PATH_DATASET)\n",
        "df[df['text'].isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YDOfSPGvqYRO",
        "outputId": "724c54f4-4f47-493b-f1e6-cb29fe59f780"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  score\n",
              "0      [bought, several, vitality, canned, dog, food,...    5.0\n",
              "1      [product, arrived, labeled, jumbo, salted, pea...    1.0\n",
              "2      [this, confection, around, centuries, light, p...    4.0\n",
              "3      [if, looking, secret, ingredient, robitussin, ...    2.0\n",
              "4      [great, taffy, great, price, there, wide, asso...    5.0\n",
              "...                                                  ...    ...\n",
              "35165  [once, tasted, hazelnut, coffee, hooked, now, ...    5.0\n",
              "35166  [has, maxwell, house, quit, making, coffee, ca...    5.0\n",
              "35167  [nutty, smooth, subtle, wonderful, aroma, love...    5.0\n",
              "35168  [price, right, taste, good, we, buying, harmon...    5.0\n",
              "35169  [this, sauce, gives, authentic, tonkatsu, flav...    5.0\n",
              "\n",
              "[35170 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3170b50e-3db8-48aa-bff1-3a7e99f8937c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[this, confection, around, centuries, light, p...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[if, looking, secret, ingredient, robitussin, ...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[great, taffy, great, price, there, wide, asso...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35165</th>\n",
              "      <td>[once, tasted, hazelnut, coffee, hooked, now, ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35166</th>\n",
              "      <td>[has, maxwell, house, quit, making, coffee, ca...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35167</th>\n",
              "      <td>[nutty, smooth, subtle, wonderful, aroma, love...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35168</th>\n",
              "      <td>[price, right, taste, good, we, buying, harmon...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35169</th>\n",
              "      <td>[this, sauce, gives, authentic, tonkatsu, flav...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35170 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3170b50e-3db8-48aa-bff1-3a7e99f8937c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3170b50e-3db8-48aa-bff1-3a7e99f8937c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3170b50e-3db8-48aa-bff1-3a7e99f8937c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "def convert_to_list(row):\n",
        "  try:\n",
        "    return list(row.split(\",\"))\n",
        "  except:\n",
        "    print(row)\n",
        "\n",
        "df.text = df.text.apply(convert_to_list)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNqUethGgqcb",
        "outputId": "3039a4ff-abd1-4a79-9bfa-4696f14a9a03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['product',\n",
              " 'arrived',\n",
              " 'labeled',\n",
              " 'jumbo',\n",
              " 'salted',\n",
              " 'peanuts',\n",
              " 'peanuts',\n",
              " 'actually',\n",
              " 'small',\n",
              " 'sized',\n",
              " 'unsalted',\n",
              " 'not',\n",
              " 'sure',\n",
              " 'error',\n",
              " 'vendor',\n",
              " 'intended',\n",
              " 'represent',\n",
              " 'product',\n",
              " 'jumbo']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.text.iloc[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGtVCXZW1PVM"
      },
      "source": [
        "# Model - Text Classification\n",
        "\n",
        "The challenge of text classification is to “learn” this categorization from a\n",
        "collection of examples for each of these categories and predict the categories for new,\n",
        "unseen products and new customer reviews.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ylG1eR-ebSl"
      },
      "source": [
        "## A Simple Classifier Without the Text Classification Pipeline: lexicon-based sentiment analysis\n",
        "\n",
        "The **AFINN** lexicon is a list of **English terms** manually rated for valence with an integer between -5 (negative) and +5 (positive) by Finn Årup Nielsen between 2009 and 2011.\n",
        "\n",
        "https://arxiv.org/pdf/1103.2903.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxpueRQ-y2Np"
      },
      "outputs": [],
      "source": [
        "!pip install afinn\n",
        "from afinn import Afinn\n",
        "afinn = Afinn(emoticons=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20-GwoObheKJ"
      },
      "outputs": [],
      "source": [
        "def apply_afinn(row):\n",
        "  score = 0\n",
        "  try:\n",
        "    for word in row:\n",
        "      score += afinn.score(word)\n",
        "  except:\n",
        "    print(row)\n",
        "    \n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw3kpat0fHJf"
      },
      "outputs": [],
      "source": [
        "len(df.text.iloc[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-254rMId8oE"
      },
      "outputs": [],
      "source": [
        "apply_afinn(df.text.iloc[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgtA4r4_nsDg"
      },
      "outputs": [],
      "source": [
        "df['afinn'] = df[\"text\"].apply(apply_afinn) #new attribute/column \n",
        "#check out how apply works\n",
        "\n",
        "df[['score', 'afinn', 'text']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APU_kpMKNcbj"
      },
      "outputs": [],
      "source": [
        "df.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc-TWJwTqKno"
      },
      "outputs": [],
      "source": [
        "df.afinn.value_counts() # df. column_name .value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VGnyF500brV"
      },
      "outputs": [],
      "source": [
        "#let's compute the range of afinn scores in this dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ApyIWfZhJuE"
      },
      "outputs": [],
      "source": [
        "abs(min(df.afinn.value_counts().index.astype(int)) - max(df.afinn.value_counts().index.astype(int)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJZYRjCXwnuG"
      },
      "outputs": [],
      "source": [
        "#let's visualize the histogram of frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orPvcK1IwrbI"
      },
      "outputs": [],
      "source": [
        "df.afinn.plot(kind='hist', #takes the column name as input\n",
        "        alpha=0.7,\n",
        "        bins = abs(min(df.afinn.value_counts().index.astype(int)) - max(df.afinn.value_counts().index.astype(int)))-1,\n",
        "        title='Histogram Of Afinn scores',\n",
        "        rot=45,\n",
        "        grid=True,\n",
        "        figsize=(12,8),\n",
        "        fontsize=12, \n",
        "        color=['#364F6B'])\n",
        "plt.xlabel('Afinn Scores')\n",
        "plt.ylabel(\"Number of Sentences\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_e6JBqW03Hd"
      },
      "outputs": [],
      "source": [
        "#let's check the distribution of sentiment values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XMrnzDAflOh"
      },
      "outputs": [],
      "source": [
        "df.score.value_counts() #df. column_name .value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKtIvTlep4J0"
      },
      "outputs": [],
      "source": [
        "confusion = pd.crosstab(df.score, df.afinn) #confusion matrix\n",
        "confusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFuA0zI0jHpy"
      },
      "source": [
        "compute a 3-class confusion matrix \n",
        "- positive (+1) \n",
        "- neutral (0) \n",
        "- negative (-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsPqlljUrEEw"
      },
      "outputs": [],
      "source": [
        "# Compute 3-class confusion matrix\n",
        "confusion = pd.crosstab(np.sign(df.score - 3), \n",
        "                        np.sign(df.afinn))\n",
        "confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7SisYdJrSzc"
      },
      "outputs": [],
      "source": [
        "shw = plt.imshow(confusion)\n",
        "bar = plt.colorbar(shw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi4hM95-rzXu"
      },
      "outputs": [],
      "source": [
        "accuracy_3_class = np.sum(np.diag(confusion)) / np.sum(confusion.values)\n",
        "accuracy_3_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-UNZ6WdjUhT"
      },
      "source": [
        " we compute a 2-class confusion matrix excluding neutral sentiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN9wD-81sAUP"
      },
      "outputs": [],
      "source": [
        "# Compute 2-class confusion matrix\n",
        "confusion_2_class = confusion.iloc[[0, 2], [0, 2]] #beware! \n",
        "confusion_2_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aydmSAe4jYf3"
      },
      "outputs": [],
      "source": [
        "shw = plt.imshow(confusion_2_class)\n",
        "bar = plt.colorbar(shw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjg-N_5zHCHC"
      },
      "source": [
        "How much is the accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrGmlnZtsCTq"
      },
      "outputs": [],
      "source": [
        "accuracy_2_class = np.sum(np.diag(confusion_2_class)) / np.sum(confusion_2_class.values)\n",
        "accuracy_2_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrM01sKPt3IP"
      },
      "source": [
        "Use as **baseline** the most frequent class: it gives better results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLw_jy27sD5-"
      },
      "outputs": [],
      "source": [
        "accuracy_2_class_baseline = confusion_2_class.sum().max() / np.sum(confusion_2_class.values)\n",
        "accuracy_2_class_baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fe_5tGKj-4R"
      },
      "source": [
        "### Custom lexicon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sd7rLk-j_lg"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/mhbashari/NRC-Persian-Lexicon\n",
        "!mv \"/content/NRC-Persian-Lexicon/NRC-Emotion-Lexicon-v0.92-InManyLanguages-web.xlsx\" \"/content/NRC-Emotion-Lexicon-v0.92-InManyLanguages-web.xlsx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3CqttQBzlw1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# import the lexicon\n",
        "lexicon_df = pd.read_excel(\"NRC-Emotion-Lexicon-v0.92-InManyLanguages-web.xlsx\", engine=\"openpyxl\")\n",
        "\n",
        "#many languages\n",
        "#8 emotion types\n",
        "#https://github.com/sebastianruder/emotion_proposition_store/tree/master/NRC-Emotion-Lexicon-v0.92\n",
        "\n",
        "\n",
        "#The NRC emotion lexicon is a list of words and their associations with\n",
        "#eight emotions (anger, fear, anticipation, trust, surprise, sadness,\n",
        "#joy, and disgust) and two sentiments (negative and positive). The\n",
        "#annotations were manually done through Amazon's Mechanical Turk. Refer\n",
        "#to publications below for more details: http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm \n",
        "\n",
        "\n",
        "lexicon_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz5x4uUQ0lpx"
      },
      "outputs": [],
      "source": [
        "# create a dict mapping word to value\n",
        "lexicon = {}\n",
        "\n",
        "#https://www.w3schools.com/python/ref_func_zip.asp\n",
        "\n",
        "for word, pos, neg in zip(lexicon_df[\"English Word\"], lexicon_df[\"Positive\"], lexicon_df[\"Negative\"]):\n",
        "  if pos:\n",
        "    value = 1\n",
        "  elif neg:\n",
        "    value = -1 #i do not consider 0's \n",
        "  else:\n",
        "    continue\n",
        "  lexicon[str(word).lower()] = value #lower case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDMGrQYy1byb"
      },
      "outputs": [],
      "source": [
        "# this custom function will return the sentiment associated to a sentence via the sum of single words\n",
        "def myscore(sentence):\n",
        "  sentiment = 0\n",
        "  for word in sentence: \n",
        "    sentiment += lexicon.get(word.lower()) if lexicon.get(word.lower()) is not None else 0 #+= operator\n",
        "  return sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7x_-cuZ2AxO"
      },
      "outputs": [],
      "source": [
        "# apply myscore function\n",
        "df['myscore'] = df[\"text\"].apply(myscore)\n",
        "df[['score', 'afinn','myscore', 'text']].tail(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgwFu6j82_dU"
      },
      "outputs": [],
      "source": [
        "confusion = pd.crosstab(np.sign(df.score - 3), np.sign(df.myscore))\n",
        "confusion_2_class = confusion.iloc[[0, 2], [0, 2]]\n",
        "confusion_2_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oFxBIVYm3R8"
      },
      "outputs": [],
      "source": [
        "shw = plt.imshow(confusion_2_class)\n",
        "bar = plt.colorbar(shw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Tclze142_dc"
      },
      "outputs": [],
      "source": [
        "accuracy_2_class = np.sum(np.diag(confusion_2_class)) / np.sum(confusion_2_class.values)\n",
        "accuracy_2_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk2Q_UYym_Kd"
      },
      "source": [
        "lower than the baseline (0.9219343235862253)! BEWARE\n",
        "\n",
        "what about the confusion matrix between the afinn score and the new score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxm5G2mhnMR4"
      },
      "outputs": [],
      "source": [
        "confusion = pd.crosstab(np.sign(df.afinn - 3), np.sign(df.myscore))\n",
        "confusion_2_class = confusion.iloc[[0, 2], [0, 2]]\n",
        "confusion_2_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_29-5wLnMR5"
      },
      "outputs": [],
      "source": [
        "shw = plt.imshow(confusion_2_class)\n",
        "bar = plt.colorbar(shw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIk7KeuTnMR5"
      },
      "outputs": [],
      "source": [
        "accuracy_2_class = np.sum(np.diag(confusion_2_class)) / np.sum(confusion_2_class.values)\n",
        "accuracy_2_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3tAD6YvqHLy"
      },
      "source": [
        "## Feature Engeneering and standard ML classifiers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.score.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImnxseH5-LQP",
        "outputId": "7e076473-d96d-4f76-b672-3aadd5f7fde3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0    22015\n",
              "4.0     5071\n",
              "1.0     3218\n",
              "3.0     2860\n",
              "2.0     2006\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_by_score(score_value, number_of_instances, data):\n",
        "  return data[data == score_value].sample(number_of_instances, random_state=1).index.to_list()"
      ],
      "metadata": {
        "id": "ALZDkfA2mKHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZXHf8YSwKQw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Step 1: train-test split\n",
        "X = df.text\n",
        "#the column text contains textual data to extract features from.\n",
        "y = df.score\n",
        "#this is the column we are learning to predict.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train.value_counts()"
      ],
      "metadata": {
        "id": "Tren10lHEUS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indx = []\n",
        "# for i in range(1,6):\n",
        "#   indx.extend(balance_by_score(i, 1628, y_train))\n",
        "\n",
        "# len(indx)"
      ],
      "metadata": {
        "id": "y_7ymBRGDqcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def intersection(lst1, lst2):\n",
        "#     return list(set(lst1) & set(lst2))\n",
        "\n",
        "# len(intersection(X_train.index.to_list(), indx))"
      ],
      "metadata": {
        "id": "c-LE4nh6F6qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = X_train.loc[indx]\n",
        "# y_train = y_train.loc[indx]"
      ],
      "metadata": {
        "id": "BxiqWsc-Edag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aflChzvwuk7",
        "outputId": "6a6ab39d-33dc-47a0-8454-a5c0b56eb32e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28136, 5000) (7034, 5000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#Step 2-3: Pre-process and Vectorize train and test data\n",
        "vect = CountVectorizer(stop_words=None, lowercase=True, max_features=5000)\n",
        "#clean is a function we defined for pre-processing, seen in the notebook.\n",
        "X_train_dtm = vect.fit_transform(X_train.apply(lambda x: \" \".join(x)))\n",
        "X_test_dtm = vect.transform(X_test.apply(lambda x: \" \".join(x)))\n",
        "print(X_train_dtm.shape, X_test_dtm.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-WR2fNeKF2r"
      },
      "outputs": [],
      "source": [
        "def analisys(y_test, y_pred_class):\n",
        "  print(\"\\n Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
        "  print(\"Report: \\n\",classification_report(y_test, y_pred_class))\n",
        "\n",
        "  cm = confusion_matrix(y_test, y_pred_class)\n",
        "\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                display_labels=[1,2,3,4,5])\n",
        "\n",
        "  disp.plot()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5apqRgrK2WOG"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def svm_classifier(X_train_balanced, y_train_balanced, X_ts, y_ts):\n",
        "  classifier = LinearSVC() \n",
        "  classifier.fit(X_train_balanced, y_train_balanced) #fit the model with training data\n",
        "  y_pred_class = classifier.predict(X_ts)\n",
        "  analisys(y_ts, y_pred_class)\n",
        "\n",
        "def mnb_classifier(X_train_balanced, y_train_balanced, X_ts, y_ts):\n",
        "  nb = MultinomialNB() #instantiate a Multinomial Naive Bayes classifier\n",
        "  nb.fit(X_train_balanced, y_train_balanced)#train the mode\n",
        "  y_pred_class = nb.predict(X_ts)#make class predictions for test data\n",
        "  analisys(y_ts, y_pred_class)\n",
        "\n",
        "def lr_classifier(X_train_balanced, y_train_balanced, X_ts, y_ts):\n",
        "  logreg = LogisticRegression(max_iter=10000)\n",
        "  logreg.fit(X_train_balanced, y_train_balanced)\n",
        "  y_pred_class = logreg.predict(X_ts)\n",
        "  analisys(y_ts, y_pred_class)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLTrH--Q5OaM"
      },
      "source": [
        "### Balancig Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkIu1-Ua5QtX"
      },
      "source": [
        "https://imbalanced-learn.org/stable/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWCcoswS5TYB",
        "outputId": "9d608a10-f5f7-4ef8-ba92-e241e819b7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn\n",
        "from imblearn.over_sampling import *\n",
        "from imblearn.under_sampling import *\n",
        "from imblearn.combine import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDozweRxNu3X"
      },
      "outputs": [],
      "source": [
        "def balancing_data(method, X_train_not_balanced, y_train_not_balanced):\n",
        "  autopct = \"%.2f\"\n",
        "  fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
        "  y_train_not_balanced.value_counts().plot.pie(autopct=autopct, ax=axs[0])\n",
        "  axs[0].set_title(\"Original\")\n",
        "  X_train_balanced, y_train_balanced = method.fit_resample(X_train_not_balanced, y_train_not_balanced)\n",
        "  y_train_balanced.value_counts().plot.pie(autopct=autopct, ax=axs[1])\n",
        "  axs[1].set_title(\"Balanced\")\n",
        "  fig.tight_layout()\n",
        "  print(y_train_balanced.value_counts())\n",
        "  return X_train_balanced, y_train_balanced"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_balanced, y_train_balanced = balancing_data(BorderlineSMOTE(random_state=42), X_train_dtm, y_train)"
      ],
      "metadata": {
        "id": "5cqdROJDeJDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Ly1fJ-vHil"
      },
      "source": [
        "### Naive Bayes Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFi8iND_mVO8"
      },
      "outputs": [],
      "source": [
        "mnb_classifier(X_train_balanced, y_train_balanced, X_test_dtm, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3upTXRZCede"
      },
      "source": [
        "### Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTKq6yDB3NQV"
      },
      "outputs": [],
      "source": [
        "lr_classifier(X_train_balanced, y_train_balanced, X_test_dtm, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTT1qgNTL9-3"
      },
      "source": [
        "### Support Vector Machine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBL4gCA1L-eg"
      },
      "outputs": [],
      "source": [
        "svm_classifier(X_train_balanced, y_train_balanced, X_test_dtm, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMwlVXWEab0G"
      },
      "source": [
        "## Using Neural Embeddings in Text Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiky-wImhRWd"
      },
      "source": [
        "### Word Embeddings\n",
        "We use [GoogleNews-vectors-negative300](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/view?resourcekey=0-wjGZdNAUop6WykTtMip30g). This is a large model that can be seen as a dictionary where the keys are words in the\n",
        "vocabulary and the values are their learned embedding representations. Given a\n",
        "query word, if the word’s embedding is present in the dictionary, it will return the\n",
        "same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J305tpX0jbZ1"
      },
      "outputs": [],
      "source": [
        "data_path= PATH_PROJ + \"GoogleNews-vectors-negative300.bin\" # from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/view?resourcekey=0-wjGZdNAUop6WykTtMip30g\n",
        "# !cp $data_path \"/content/GoogleNews-vectors-negative300.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yiURyGoXHdC",
        "outputId": "519882e6-953d-4eea-9f05-e006aa886143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done loading Word2Vec\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "#Load W2V model. This will take some time.\n",
        "w2v_model = KeyedVectors.load_word2vec_format(data_path, binary=True)\n",
        "print('done loading Word2Vec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BNSQZ7zuP6g"
      },
      "source": [
        "How do we use this pre-learned embedding to represent features? A simple approach is just\n",
        "to average the embeddings for individual words in text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBLPKwSfuQF-"
      },
      "outputs": [],
      "source": [
        "# Creating a feature vector by averaging all embeddings for all sentences\n",
        "def embedding_feats(list_of_lists, w2v_model):\n",
        "  DIMENSION = 300\n",
        "  zero_vector = np.zeros(DIMENSION)\n",
        "  feats = []\n",
        "  for tokens in list_of_lists:\n",
        "    feat_for_this = np.zeros(DIMENSION)\n",
        "    count_for_this = 0\n",
        "    \n",
        "    for token in tokens:\n",
        "      if token in w2v_model:\n",
        "        feat_for_this += w2v_model[token]\n",
        "        count_for_this +=1\n",
        "    \n",
        "    feats.append(feat_for_this/count_for_this)\n",
        "    \n",
        "  return feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFCZHGKGvcNQ",
        "outputId": "bda3cb15-e6b3-43fb-f399-38d176cd7597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28136\n",
            "7034\n"
          ]
        }
      ],
      "source": [
        "train_vectors = embedding_feats(X_train, w2v_model)\n",
        "print(len(train_vectors))\n",
        "test_vectors = embedding_feats(X_test, w2v_model)\n",
        "print(len(test_vectors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmDMJUg__Ebe"
      },
      "outputs": [],
      "source": [
        "X_train_balanced, y_train_balanced = balancing_data(BorderlineSMOTE(random_state=42), train_vectors, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCI8q143vn23",
        "outputId": "035c2b8e-54a3-45c9-d825-e5454437f667"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], shape=(0, 2), dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ],
      "source": [
        "np.argwhere(np.isnan(np.array(train_vectors)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgYmPgvG8GD2"
      },
      "source": [
        "We treat the resulting\n",
        "embedding vector as the feature vector that represents the entire text. Once this feature engineering is done, the final step is similar to what we did in the previous section: use these features and train a classifier. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9QOPJ8D40yu"
      },
      "source": [
        "### Naive Bayes Classifier\n",
        "\n",
        "Naive bayes classifier does not allow for negative values in the document vectors. But when we use document+word vectors, Z will have some negatives. It should be possible to translate/scale all vectors uniformly to avoid negatives, but we do not bother as we have enough simulations to run anyway. So basically naive bayes classifier is used ONLY with pure document vectors here.\n",
        "\n",
        "credits: https://towardsdatascience.com/word-embeddings-and-document-vectors-when-in-doubt-simplify-8c9aaeec244e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isUhz_3M40yv"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_balanced_for_mnb = scaler.fit_transform(X_train_balanced)\n",
        "X_ts_for_mnb = scaler.transform(test_vectors)\n",
        "\n",
        "\n",
        "mnb_classifier(X_train_balanced_for_mnb, y_train_balanced, X_ts_for_mnb, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj-deP1g40yv"
      },
      "source": [
        "### Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAF46G9N40yv"
      },
      "outputs": [],
      "source": [
        "lr_classifier(X_train_balanced, y_train_balanced, test_vectors, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLMqCcJT40yw"
      },
      "source": [
        "### Support Vector Machine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXfviWUK40yw"
      },
      "outputs": [],
      "source": [
        "svm_classifier(X_train_balanced, y_train_balanced, test_vectors, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subword Embeddings and fastText\n",
        "\n",
        "FastText embeddings are based on the idea of\n",
        "enriching word embeddings with subword-level information. Thus, the embedding\n",
        "representation for each word is represented as a sum of the representations of individual character n-grams. While fastText is a general-purpose library to learn the embeddings, it also supports\n",
        "off-the-shelf text classification by providing end-to-end classifier training and testing;\n",
        "i.e., we don’t have to handle feature extraction separately. \n",
        "\n",
        "https://en.wikipedia.org/wiki/FastText\n"
      ],
      "metadata": {
        "id": "bTmD2hRNN4Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_DATASET = PATH_PROJ+\"food.csv\""
      ],
      "metadata": {
        "id": "xwoYXtCBSOj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(PATH_DATASET)"
      ],
      "metadata": {
        "id": "jACNNx1qSTiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext==0.9.2\n"
      ],
      "metadata": {
        "id": "js3vcuLSN8mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c9aa66-ce58-4f5f-ccde-3f40eed95867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fasttext==0.9.2 in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (2.10.4)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the first step\n",
        "involves cleaning the text to\n",
        "remove extraneous characters, similar to what we did in the pre-processing steps for\n",
        "the other classifier examples we’ve seen so far."
      ],
      "metadata": {
        "id": "IXuX_LWWRkiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets do some cleaning of this text\n",
        "def clean_it(text,normalize=True):\n",
        "    # Replacing possible issues with data. We can add or reduce the replacemtent in this chain\n",
        "    s = str(text).replace(',',' ').replace('\"','').replace('\\'',' \\' ').replace('.',' . ').replace('(',' ( ').\\\n",
        "            replace(')',' ) ').replace('!',' ! ').replace('?',' ? ').replace(':',' ').replace(';',' ').lower()\n",
        "    \n",
        "    # normalizing / encoding the text\n",
        "    if normalize:\n",
        "        s = s.normalize('NFKD').str.encode('ascii','ignore').str.decode('utf-8')\n",
        "    \n",
        "    return s\n",
        "\n",
        "# Now lets define a small function where we can use above cleaning on datasets\n",
        "def clean_df(data, cleanit= False, shuffleit=False, encodeit=False, label_prefix='__class__'):\n",
        "    # Defining the new data\n",
        "    df = data[['text']].copy(deep=True)\n",
        "    df['score'] = label_prefix + data['score'].astype(str) + ' '\n",
        "    \n",
        "    # cleaning it\n",
        "    if cleanit:\n",
        "        df['text'] = df['text'].apply(lambda x: clean_it(x,encodeit))\n",
        "    \n",
        "    # shuffling it\n",
        "    if shuffleit:\n",
        "        df.sample(frac=1).reset_index(drop=True)\n",
        "            \n",
        "    return df"
      ],
      "metadata": {
        "id": "mognZtM4RPPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU_HOQSeUDjh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(df, random_state=1, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_cleaned = clean_df(df_train, True, True)\n",
        "df_train_cleaned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "W7EG39zoS8As",
        "outputId": "17b757dc-f846-4c6a-e3d2-a48326d28778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text          score\n",
              "6584   these are really good !  !  !   also  be sure ...  __class__5.0 \n",
              "22631  this is among the best sencha i have had .  ma...  __class__5.0 \n",
              "10870  great flavor .   i snack on these when i need ...  __class__5.0 \n",
              "31464  although the size of the can is deceiving  ( o...  __class__5.0 \n",
              "24686  the fda has issued a warning about pet treats ...  __class__1.0 \n",
              "...                                                  ...            ...\n",
              "7813   i ' m not vegetarian  but i ' m on the fat sma...  __class__4.0 \n",
              "32511  i love this cereal .   it is sweetened with mo...  __class__5.0 \n",
              "5192   great price and my cat loves this food .   he ...  __class__5.0 \n",
              "12172  i am always feeding my dogs chicken jerky  i l...  __class__5.0 \n",
              "33003  i have taken goji berries for several years no...  __class__5.0 \n",
              "\n",
              "[28137 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd15f1c6-0425-468e-9e52-90b7f15bd2dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6584</th>\n",
              "      <td>these are really good !  !  !   also  be sure ...</td>\n",
              "      <td>__class__5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22631</th>\n",
              "      <td>this is among the best sencha i have had .  ma...</td>\n",
              "      <td>__class__5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10870</th>\n",
              "      <td>great flavor .   i snack on these when i need ...</td>\n",
              "      <td>__class__5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31464</th>\n",
              "      <td>although the size of the can is deceiving  ( o...</td>\n",
              "      <td>__class__5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24686</th>\n",
              "      <td>the fda has issued a warning about pet treats ...</td>\n",
              "      <td>__class__1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7813</th>\n",
              "      <td>i ' m not vegetarian  but i ' m on the fat sma...</td>\n",
              "      <td>__class__4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32511</th>\n",
              "      <td>i love this cereal .   it is sweetened with mo...</td>\n",
              "      <td>__class__5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5192</th>\n",
              "      <td>great price and my cat loves this food .   he ...</td>\n",
              "      <td>__class__5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12172</th>\n",
              "      <td>i am always feeding my dogs chicken jerky  i l...</td>\n",
              "      <td>__class__5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33003</th>\n",
              "      <td>i have taken goji berries for several years no...</td>\n",
              "      <td>__class__5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28137 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd15f1c6-0425-468e-9e52-90b7f15bd2dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd15f1c6-0425-468e-9e52-90b7f15bd2dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd15f1c6-0425-468e-9e52-90b7f15bd2dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_cleaned = clean_df(df_test, True, True)\n",
        "df_test_cleaned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_MGBCGbPTe6S",
        "outputId": "aecc83dc-1ea4-4ae9-b3e1-3aaeffc7c699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text          score\n",
              "15799  i really like nantucket blend .   i drink way ...  __class__1.0 \n",
              "5828   hi  i ordered this product from another websit...  __class__3.0 \n",
              "23130  smooth coffee with rich  flavorful aroma  alon...  __class__2.0 \n",
              "9609   fondarific usually has glowing reviews .  .  ....  __class__1.0 \n",
              "16266  the price was awesome  the shipping was incred...  __class__5.0 \n",
              "...                                                  ...            ...\n",
              "1785   love these pop-chips !  the variety bag was a ...  __class__5.0 \n",
              "16901  i like the idea behind this product  but the t...  __class__3.0 \n",
              "32457  i have been giving these chews to my mini-pinc...  __class__1.0 \n",
              "20844  we brought this product home from jamaica and ...  __class__5.0 \n",
              "30588  the monitors won ' t let me tell you where i p...  __class__3.0 \n",
              "\n",
              "[7035 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3045c1bc-60f3-4d62-9154-f46534b70055\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15799</th>\n",
              "      <td>i really like nantucket blend .   i drink way ...</td>\n",
              "      <td>__class__1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5828</th>\n",
              "      <td>hi  i ordered this product from another websit...</td>\n",
              "      <td>__class__3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23130</th>\n",
              "      <td>smooth coffee with rich  flavorful aroma  alon...</td>\n",
              "      <td>__class__2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9609</th>\n",
              "      <td>fondarific usually has glowing reviews .  .  ....</td>\n",
              "      <td>__class__1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16266</th>\n",
              "      <td>the price was awesome  the shipping was incred...</td>\n",
              "      <td>__class__5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1785</th>\n",
              "      <td>love these pop-chips !  the variety bag was a ...</td>\n",
              "      <td>__class__5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16901</th>\n",
              "      <td>i like the idea behind this product  but the t...</td>\n",
              "      <td>__class__3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32457</th>\n",
              "      <td>i have been giving these chews to my mini-pinc...</td>\n",
              "      <td>__class__1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20844</th>\n",
              "      <td>we brought this product home from jamaica and ...</td>\n",
              "      <td>__class__5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30588</th>\n",
              "      <td>the monitors won ' t let me tell you where i p...</td>\n",
              "      <td>__class__3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7035 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3045c1bc-60f3-4d62-9154-f46534b70055')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3045c1bc-60f3-4d62-9154-f46534b70055 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3045c1bc-60f3-4d62-9154-f46534b70055');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write files to disk as fastText classifier API reads files from disk.\n",
        "train_file = PATH_PROJ + '/fasttext_train.csv'\n",
        "df_train_cleaned.to_csv(train_file, header=None, index=False, columns=['score','text'] )\n",
        "\n",
        "test_file = PATH_PROJ + '/fasttext_test.csv'\n",
        "df_test_cleaned.to_csv(test_file, header=None, index=False, columns=['score','text'])"
      ],
      "metadata": {
        "id": "q6983g0xUjrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the train and test files written into disk in a format fastText wants, we are ready to use it for text classification!"
      ],
      "metadata": {
        "id": "dPUV0l7CU0n_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "## Using fastText for feature extraction and training\n",
        "from fasttext import train_supervised \n",
        "\"\"\"fastText expects and training file (csv), a model name as input arguments.\n",
        "label_prefix refers to the prefix before label string in the dataset.\n",
        "default is __label__. In our dataset, it is __class__. \n",
        "There are several other parameters which can be seen in: \n",
        "https://pypi.org/project/fasttext/\n",
        "\"\"\"\n",
        "\n",
        "model = train_supervised(input=train_file, label=\"__class__\", lr=1.0, epoch=75, loss='ova', wordNgrams=2, dim=200, thread=2, verbose=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91pA8NlwUpsJ",
        "outputId": "6bb1be46-f4ba-4057-f045-d92d08f3c6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5min 38s, sys: 4.69 s, total: 5min 43s\n",
            "Wall time: 3min 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score_compute(precision, recall):\n",
        "  return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Precision = True Positive / (True Positive + False Positive) \n",
        "# Recall = True Positive / (True Positive + False Negative) \n",
        "# F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "for k in range(1,6):\n",
        "  results = model.test(test_file,k=k) # you should specify k parameter to get the top-k predicted classes. DOC: https://fasttext.cc/docs/en/supervised-tutorial.html#advanced-readers-precision-and-recall\n",
        "  recall = results[2]*100\n",
        "  precision = results[1]*100\n",
        "  f1 = f1_score_compute(precision, recall)\n",
        "  print(f\"Test Samples: {results[0]} Precision@{k} : {results[1]*100:2.4f} Recall@{k} : {results[2]*100:2.4f}  --- F1_score@{k}: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN9JK9-SU-to",
        "outputId": "e1434e94-0539-4513-ccc2-2d3b4fdad8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Samples: 7035 Precision@1 : 72.6084 Recall@1 : 72.6084  --- F1_score@1: 72.60838663823739\n",
            "Test Samples: 7035 Precision@2 : 42.7150 Recall@2 : 85.4300  --- F1_score@2: 56.95332859511965\n",
            "Test Samples: 7035 Precision@3 : 30.6326 Recall@3 : 91.8977  --- F1_score@3: 45.94882729211087\n",
            "Test Samples: 7035 Precision@4 : 23.9090 Recall@4 : 95.6361  --- F1_score@4: 38.25444207533759\n",
            "Test Samples: 7035 Precision@5 : 20.0000 Recall@5 : 100.0000  --- F1_score@5: 33.333333333333336\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMdYu0gZIPSj4tI5GKu7Sps",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}